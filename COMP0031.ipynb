{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/interritus141/COMP0031-Group-Research-Project/blob/master/COMP0031.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruZOtW7WfjEi"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry2CiBzShB_L"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdRkLejZvwwr"
      },
      "source": [
        "## General"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XbrhDC6YfjuP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVXYGAAkvz_t"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b-C5-niIeOoE"
      },
      "outputs": [],
      "source": [
        "from ta import add_all_ta_features\n",
        "import yfinance as yf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ThdiN2zwIlb"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "x7RFmf4lj3Yt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nono/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import gym \n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3 import A2C, DDPG, DQN, PPO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmDiCGt8wMpk"
      },
      "source": [
        "## Backtesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5hCvaaWHpixR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nono/miniconda3/envs/rl_tutorial/lib/python3.10/site-packages/backtesting/_plotting.py:50: UserWarning: Jupyter Notebook detected. Setting Bokeh output to notebook. This may not work in Jupyter clients without JavaScript support (e.g. PyCharm, Spyder IDE). Reset with `backtesting.set_bokeh_output(notebook=False)`.\n",
            "  warnings.warn('Jupyter Notebook detected. '\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "        .bk-notebook-logo {\n",
              "            display: block;\n",
              "            width: 20px;\n",
              "            height: 20px;\n",
              "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
              "        }\n",
              "    </style>\n",
              "    <div>\n",
              "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
              "        <span id=\"p1001\">Loading BokehJS ...</span>\n",
              "    </div>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"p1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.0.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.0.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.0.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.0.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.0.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"p1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
            "application/vnd.bokehjs_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from backtesting import Backtest, Strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itPimO3WZcN_"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdcDd-Iqd_-Z"
      },
      "source": [
        "## Tech Indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lbA-Y5Y3grjA"
      },
      "outputs": [],
      "source": [
        "def add_ta(df):\n",
        "  ta_df = add_all_ta_features(df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\")\n",
        "  # print(ta_df.columns)\n",
        "  ta_df = ta_df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Adj Close\", \"volume_obv\",\n",
        "                                \"volume_adi\", \"trend_adx\", \"momentum_ao\", \"trend_macd\", \"momentum_rsi\", \n",
        "                                \"momentum_stoch\"]]\n",
        "  ta_df = ta_df.fillna(ta_df.mean())\n",
        "  return ta_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttJNGUWuvVF2"
      },
      "source": [
        "## Stocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3JCv_b7iw9b"
      },
      "source": [
        "1. Apple Inc. (AAPL)\n",
        "2. Microsoft Corp. (MSFT)\n",
        "3. Amazon.com, Inc. ( AMZN)\n",
        "4. Tesla, Inc. (TSLA)\n",
        "5. Nvidia Corp. (NVDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQW7POdeiKTJ",
        "outputId": "ab402ff2-b8a2-4834-a616-e8484aba3b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nono/miniconda3/envs/rl_tutorial/lib/python3.10/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dip[idx] = 100 * (self._dip[idx] / value)\n",
            "/home/nono/miniconda3/envs/rl_tutorial/lib/python3.10/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  din[idx] = 100 * (self._din[idx] / value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nono/miniconda3/envs/rl_tutorial/lib/python3.10/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dip[idx] = 100 * (self._dip[idx] / value)\n",
            "/home/nono/miniconda3/envs/rl_tutorial/lib/python3.10/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  din[idx] = 100 * (self._din[idx] / value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nono/miniconda3/envs/rl_tutorial/lib/python3.10/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dip[idx] = 100 * (self._dip[idx] / value)\n",
            "/home/nono/miniconda3/envs/rl_tutorial/lib/python3.10/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  din[idx] = 100 * (self._din[idx] / value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nono/miniconda3/envs/rl_tutorial/lib/python3.10/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dip[idx] = 100 * (self._dip[idx] / value)\n",
            "/home/nono/miniconda3/envs/rl_tutorial/lib/python3.10/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  din[idx] = 100 * (self._din[idx] / value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nono/miniconda3/envs/rl_tutorial/lib/python3.10/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dip[idx] = 100 * (self._dip[idx] / value)\n",
            "/home/nono/miniconda3/envs/rl_tutorial/lib/python3.10/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  din[idx] = 100 * (self._din[idx] / value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nono/miniconda3/envs/rl_tutorial/lib/python3.10/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dip[idx] = 100 * (self._dip[idx] / value)\n",
            "/home/nono/miniconda3/envs/rl_tutorial/lib/python3.10/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  din[idx] = 100 * (self._din[idx] / value)\n"
          ]
        }
      ],
      "source": [
        "stock_volatilities = {}\n",
        "stocks = dict.fromkeys([\"AAPL\", \"MSFT\", \"AMZN\", \"TSLA\", \"NVDA\", \"CAAS\"])\n",
        "\n",
        "for stock in stocks.keys():\n",
        "  stock_df = yf.download(stock, start=\"2018-01-01\", end=\"2022-12-31\", keepna=True)\n",
        "  stock_df = stock_df.fillna(stock_df.mean())\n",
        "  stock_df = add_ta(stock_df)\n",
        "  stocks[stock] = stock_df\n",
        "  stock_volatilities[stock] = None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_volatility(df, df_name):\n",
        "  df[\"Log returns\"] = np.log(df['Close'] / df['Close'].shift())\n",
        "  stock_volatilities[df_name] = df['Log returns'].std() * 252 ** .5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'AAPL': 0.33515159660010024, 'MSFT': 0.3108167320339789, 'AMZN': 0.35823866187984743, 'TSLA': 0.6545095345365393, 'NVDA': 0.5216282953491833, 'CAAS': 0.83977708799141}\n"
          ]
        }
      ],
      "source": [
        "def visualise_volatility(df, df_name, volatility):\n",
        "  fig, ax = plt.subplots()\n",
        "  df['Log returns'].hist(ax=ax, bins=50, alpha=0.6, color='b')\n",
        "  ax.set_xlabel(\"Log return\")\n",
        "  ax.set_ylabel(\"Freq of log return\")\n",
        "  ax.set_title(\"{:s} volatility: {:.2f}%\".format(df_name, volatility*100))\n",
        "\n",
        "for stock, stock_df in stocks.items():\n",
        "  add_volatility(stock_df, stock)\n",
        "  # visualise_volatility(stock_df, stock, stock_volatilities[stock]) // use to generate graphs\n",
        "\n",
        "print(stock_volatilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uJtS7XLJuSs2"
      },
      "outputs": [],
      "source": [
        "def add_cov(df):\n",
        "  df = df.reset_index()\n",
        "\n",
        "  cov_list = []\n",
        "  return_list = []\n",
        "\n",
        "  # look back is one year\n",
        "  lookback=252\n",
        "  for i in range(lookback,len(df.index.unique())):\n",
        "    data_lookback = df.iloc[i-lookback:i,:]\n",
        "    price_lookback=data_lookback.pivot_table(index = 'Date', values = 'Close')\n",
        "    return_lookback = price_lookback.pct_change().dropna()\n",
        "    return_list.append(return_lookback)\n",
        "\n",
        "    covs = return_lookback.cov().values \n",
        "    cov_list.append(covs)\n",
        "\n",
        "\n",
        "  df_cov = pd.DataFrame({'Date':df[\"Date\"].unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
        "  df = df.merge(df_cov, on='Date')\n",
        "  df = df.sort_values(['Date']).reset_index(drop=True)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QwlliL4VulGv"
      },
      "outputs": [],
      "source": [
        "aapl_df = stocks[\"AAPL\"]\n",
        "caas_df = stocks[\"CAAS\"]\n",
        "\n",
        "aapl_df = add_cov(aapl_df)\n",
        "caas_df = add_cov(caas_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8OADGaYLI-bv"
      },
      "outputs": [],
      "source": [
        "new_aapl_df = aapl_df.copy()\n",
        "new_aapl_df[\"tic\"] = \"AAPL\"\n",
        "new_caas_df = caas_df.copy()\n",
        "new_caas_df[\"tic\"] = \"CAAS\"\n",
        "mixed_df = pd.concat([new_aapl_df, new_caas_df])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVYjY6QFj2Uy"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XIA9Tg7bmZGN"
      },
      "outputs": [],
      "source": [
        "class StockPortfolioEnv(gym.Env):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def reset(self):\n",
        "    pass\n",
        "  \n",
        "  def step(self, action):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4kOv8W1vglS"
      },
      "source": [
        "## Kaggle Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TybILV4De-mr"
      },
      "outputs": [],
      "source": [
        "class StockPortfolioEnv(gym.Env):\n",
        "  def __init__(self, \n",
        "                df,\n",
        "                stock_dim,\n",
        "                hmax,\n",
        "                initial_amount,\n",
        "                transaction_cost_pct,\n",
        "                reward_scaling,\n",
        "                state_space,\n",
        "                action_space,\n",
        "                tech_indicator_list,\n",
        "                turbulence_threshold=None,\n",
        "                lookback=252,\n",
        "                day = 0):\n",
        "    #super(StockEnv, self).__init__()\n",
        "    #money = 10 , scope = 1\n",
        "    self.day = day\n",
        "    self.lookback=lookback\n",
        "    self.df = df\n",
        "    self.stock_dim = stock_dim\n",
        "    self.hmax = hmax\n",
        "    self.initial_amount = initial_amount\n",
        "    self.transaction_cost_pct =transaction_cost_pct\n",
        "    self.reward_scaling = reward_scaling\n",
        "    self.state_space = state_space\n",
        "    self.action_space = action_space\n",
        "    self.tech_indicator_list = tech_indicator_list\n",
        "\n",
        "    # action_space normalization and shape is self.stock_dim\n",
        "    self.action_space = gym.spaces.Box(low = -1, high = 1,shape = (self.action_space,)) \n",
        "    # Shape = ??\n",
        "    # covariance matrix + technical indicators\n",
        "    self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape = (1+len(self.tech_indicator_list),self.state_space))\n",
        "\n",
        "    # load data from a pandas dataframe\n",
        "    self.data = self.df.loc[self.day,:]\n",
        "    self.covs = [[x[0][0] for x in self.data['cov_list']]]\n",
        "    self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "    self.terminal = False     \n",
        "    self.turbulence_threshold = turbulence_threshold        \n",
        "    # initalize state: inital portfolio return + individual stock return + individual weights\n",
        "    self.portfolio_value = self.initial_amount\n",
        "\n",
        "    # memorize portfolio value each step\n",
        "    self.asset_memory = [self.initial_amount]\n",
        "    # memorize portfolio return each step\n",
        "    self.portfolio_return_memory = [0]\n",
        "    self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "    self.date_memory=[self.data[\"Date\"].unique()[0]]\n",
        "\n",
        "\n",
        "        \n",
        "  def step(self, actions):\n",
        "    # print(self.day)\n",
        "    self.terminal = self.day >= len(self.df.index.unique())/self.stock_dim-1\n",
        "    # print(actions)\n",
        "\n",
        "    if self.terminal:\n",
        "      df = pd.DataFrame(self.portfolio_return_memory)\n",
        "      df.columns = ['daily_return']\n",
        "      plt.plot(df.daily_return.cumsum(),'r')\n",
        "      # plt.savefig('results/cumulative_reward.png')\n",
        "      plt.close()\n",
        "\n",
        "      plt.plot(self.portfolio_return_memory,'r')\n",
        "      # plt.savefig('results/rewards.png')\n",
        "      plt.close()\n",
        "\n",
        "      print(\"=================================\")\n",
        "      print(\"begin_total_asset:{}\".format(self.asset_memory[0]))           \n",
        "      print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
        "\n",
        "      df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
        "      df_daily_return.columns = ['daily_return']\n",
        "      if df_daily_return['daily_return'].std() !=0:\n",
        "        sharpe = (252**0.5)*df_daily_return['daily_return'].mean()/ \\\n",
        "                  df_daily_return['daily_return'].std()\n",
        "        print(\"Sharpe: \",sharpe)\n",
        "      print(\"=================================\")\n",
        "\n",
        "      return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "    else:\n",
        "      #print(\"Model actions: \",actions)\n",
        "      # actions are the portfolio weight\n",
        "      # normalize to sum of 1\n",
        "      #if (np.array(actions) - np.array(actions).min()).sum() != 0:\n",
        "      #  norm_actions = (np.array(actions) - np.array(actions).min()) / (np.array(actions) - np.array(actions).min()).sum()\n",
        "      #else:\n",
        "      #  norm_actions = actions\n",
        "      weights = self.softmax_normalization(actions) \n",
        "      #print(\"Normalized actions: \", weights)\n",
        "      self.actions_memory.append(weights)\n",
        "      last_day_memory = self.data\n",
        "\n",
        "      #load next state\n",
        "      self.day += 1\n",
        "      self.data = self.df.loc[self.day,:]\n",
        "      self.covs = [[x[0][0] for x in self.data['cov_list']]]\n",
        "      self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "      #print(self.state)\n",
        "      # calcualte portfolio return\n",
        "      # individual stocks' return * weight\n",
        "      portfolio_return = sum(((self.data[\"Close\"].values / last_day_memory[\"Close\"].values)-1)*weights)\n",
        "      # update portfolio value\n",
        "      new_portfolio_value = self.portfolio_value*(1+portfolio_return)\n",
        "      self.portfolio_value = new_portfolio_value\n",
        "\n",
        "      # save into memory\n",
        "      self.portfolio_return_memory.append(portfolio_return)\n",
        "      self.date_memory.append(self.data[\"Date\"].unique()[0])            \n",
        "      self.asset_memory.append(new_portfolio_value)\n",
        "\n",
        "      # the reward is the new portfolio value or end portfolo value\n",
        "      self.reward = new_portfolio_value \n",
        "      #print(\"Step reward: \", self.reward)\n",
        "      #self.reward = self.reward*self.reward_scaling\n",
        "\n",
        "    return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "  def reset(self):\n",
        "    self.asset_memory = [self.initial_amount]\n",
        "    self.day = 0\n",
        "    self.data = self.df.loc[self.day,:]\n",
        "    # load states\n",
        "    self.covs = [[x[0][0] for x in self.data['cov_list']]]\n",
        "    self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "    self.portfolio_value = self.initial_amount\n",
        "    #self.cost = 0\n",
        "    #self.trades = 0\n",
        "    self.terminal = False \n",
        "    self.portfolio_return_memory = [0]\n",
        "    self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "    self.date_memory=[self.data[\"Date\"].unique()[0]] \n",
        "    return self.state\n",
        "    \n",
        "  def render(self, mode='human'):\n",
        "    return self.state\n",
        "      \n",
        "  def softmax_normalization(self, actions):\n",
        "    numerator = np.exp(actions)\n",
        "    denominator = np.sum(np.exp(actions))\n",
        "    softmax_output = numerator/denominator\n",
        "    return softmax_output\n",
        "\n",
        "  \n",
        "  def save_asset_memory(self):\n",
        "    date_list = self.date_memory\n",
        "    portfolio_return = self.portfolio_return_memory\n",
        "    #print(len(date_list))\n",
        "    #print(len(asset_list))\n",
        "    df_account_value = pd.DataFrame({'Date':date_list,'daily_return':portfolio_return})\n",
        "    return df_account_value\n",
        "\n",
        "  def save_action_memory(self):\n",
        "    # date and close price length must match actions length\n",
        "    date_list = self.date_memory\n",
        "    df_date = pd.DataFrame(date_list)\n",
        "    df_date.columns = ['Date']\n",
        "    \n",
        "    action_list = self.actions_memory\n",
        "    df_actions = pd.DataFrame(action_list)\n",
        "    df_actions.columns = self.data[\"tic\"]\n",
        "    df_actions.index = df_date[\"Date\"]\n",
        "    #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
        "    return df_actions\n",
        "\n",
        "  def _seed(self, seed=None):\n",
        "    self.np_random, seed = seeding.np_random(seed)\n",
        "    return [seed]\n",
        "\n",
        "  def get_sb_env(self):\n",
        "    e = DummyVecEnv([lambda: self])\n",
        "    obs = e.reset()\n",
        "    return e, obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xtChcI_bWwtF"
      },
      "outputs": [],
      "source": [
        "stock_dimension = len(mixed_df[\"tic\"].unique())\n",
        "state_space = 2\n",
        "\n",
        "env_kwargs = {\n",
        "  \"hmax\": 100, \n",
        "  \"initial_amount\": 1000000, \n",
        "  \"transaction_cost_pct\": 0.001, \n",
        "  \"state_space\": state_space, \n",
        "  \"stock_dim\": stock_dimension, \n",
        "  \"tech_indicator_list\": [\n",
        "    \"volume_obv\",\n",
        "    \"volume_adi\", \n",
        "    \"trend_adx\", \n",
        "    \"momentum_ao\", \n",
        "    \"trend_macd\", \n",
        "    \"momentum_rsi\", \n",
        "    \"momentum_stoch\"\n",
        "  ], \n",
        "  \"action_space\": stock_dimension, \n",
        "  \"reward_scaling\": 1e-4\n",
        "    \n",
        "}\n",
        "\n",
        "env = StockPortfolioEnv(df = mixed_df, **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7TKIReMWLo4",
        "outputId": "325554cd-798c-4e93-dd92-491b113aef94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
          ]
        }
      ],
      "source": [
        "env_train, _ = env.get_sb_env()\n",
        "print(type(env_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omTjQhJRZeNl"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "a-J1PdhqWoO5"
      },
      "outputs": [],
      "source": [
        "policy = \"MlpPolicy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2S3msd3tZiHl"
      },
      "outputs": [],
      "source": [
        "a2c_agent = A2C(policy, env)\n",
        "ddpg_agent = DDPG(policy, env)\n",
        "# dqn_agent = DQN(policy, env)\n",
        "ppo_agent = PPO(policy, env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah0dR9y0rnpk",
        "outputId": "027fda7d-bc7a-4f52-fb22-a2c44b58cc5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A2C\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:7443887.522852576\n",
            "Sharpe:  1.3400262921658477\n",
            "=================================\n",
            "DDPG\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3091683.5375167835\n",
            "Sharpe:  1.5187126923495782\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3447947.315054475\n",
            "Sharpe:  1.5721348164384883\n",
            "=================================\n",
            "PPO\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3372882.5497302217\n",
            "Sharpe:  1.078663876598181\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2604376.851751992\n",
            "Sharpe:  1.1577008435463798\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3653793.774667323\n",
            "Sharpe:  1.1130476083249339\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4292454.190860367\n",
            "Sharpe:  1.4285412835457854\n",
            "=================================\n"
          ]
        }
      ],
      "source": [
        "print(\"A2C\")\n",
        "a2c_result = a2c_agent.learn(\n",
        "    total_timesteps=1000,\n",
        ")\n",
        "\n",
        "print(\"DDPG\")\n",
        "ddpg_result = ddpg_agent.learn(\n",
        "    total_timesteps=1000,\n",
        ")\n",
        "\n",
        "print(\"PPO\")\n",
        "ppo_result = ppo_agent.learn(\n",
        "    total_timesteps=1000,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYsyJqelllWu"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p6UtUfzlr4o",
        "outputId": "e8e4ea4c-bbd5-45d1-a29b-0e94b4811d35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3911955.159962247\n",
            "Sharpe:  1.1241209839537307\n",
            "=================================\n"
          ]
        }
      ],
      "source": [
        "a2c_vec_env = a2c_result.get_env()\n",
        "obs = a2c_vec_env.reset()\n",
        "for i in range(1000):\n",
        "    action, _states = a2c_result.predict(obs, deterministic=True)\n",
        "    obs, reward, done, info = a2c_vec_env.step(action)\n",
        "    # print(\"Step\", i, reward)\n",
        "    a2c_vec_env.render()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVPD5FMypfzK"
      },
      "source": [
        "# Backtest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PbDvUnSvmgr"
      },
      "source": [
        "## To explore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oqXC_4rFpoVy"
      },
      "outputs": [],
      "source": [
        "class MLTrainOnceStrategy(Strategy):\n",
        "    price_delta = .004  # 0.4%\n",
        "\n",
        "    def init(self):        \n",
        "        # agent\n",
        "        self.agent = ppo_result\n",
        "        self.vec_env = ppo_result.get_env()\n",
        "        self.obs = self.vec_env.reset()\n",
        "        \n",
        "        # data\n",
        "        # self.data = mixed_df\n",
        "        # self.data.set_index(\"Date\")\n",
        "\n",
        "        # Prepare empty, all-NaN forecast indicator\n",
        "        self.forecasts = self.I(lambda: np.repeat(np.nan, len(self.data)), name='forecast')\n",
        "    \n",
        "    def next(self):\n",
        "        # Proceed only with out-of-sample data. Prepare some variables\n",
        "        high, low, close = self.data.High, self.data.Low, self.data.Close\n",
        "        # current_time = self.data.index[-1]\n",
        "\n",
        "        # Forecast the next movement\n",
        "        action, _states = self.agent.predict(self.obs, deterministic=True)\n",
        "        self.obs, forecast, done, info = self.vec_env.step(action)\n",
        "        self.vec_env.render()\n",
        "\n",
        "        # Update the plotted \"forecast\" indicator\n",
        "        self.forecasts[-1] = forecast\n",
        "\n",
        "        # If our forecast is upwards and we don't already hold a long position\n",
        "        # place a long order for 20% of available account equity. Vice versa for short.\n",
        "        # Also set target take-profit and stop-loss prices to be one price_delta\n",
        "        # away from the current closing price.\n",
        "        upper, lower = close[-1] * (1 + np.r_[1, -1]*self.price_delta)\n",
        "\n",
        "        if forecast > 1000000 and not self.position.is_long:\n",
        "            self.buy(size=.2, tp=upper, sl=lower)\n",
        "        elif forecast <= 1000000 and not self.position.is_short:\n",
        "            self.sell(size=.2, tp=lower, sl=upper)\n",
        "\n",
        "        # Additionally, set aggressive stop-loss on trades that have been open \n",
        "        # for more than two days\n",
        "        # for trade in self.trades:\n",
        "        #     if current_time - trade.entry_time > pd.Timedelta('2 days'):\n",
        "        #         if trade.is_long:\n",
        "        #             trade.sl = max(trade.sl, low)\n",
        "        #         else:\n",
        "        #             trade.sl = min(trade.sl, high)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0JeqSBvsKGV",
        "outputId": "67234d8a-3b1e-453a-90b5-31aa3692b199"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_20358/3738323711.py:1: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
            "  bt = Backtest(aapl_df, MLTrainOnceStrategy, commission=.0002, margin=.05)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4073994.519489919\n",
            "Sharpe:  1.2170505454007223\n",
            "=================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Start                                     0.0\n",
              "End                                    1006.0\n",
              "Duration                               1006.0\n",
              "Exposure Time [%]                   62.264151\n",
              "Equity Final [$]                    32.985181\n",
              "Equity Peak [$]                       10000.0\n",
              "Return [%]                         -99.670148\n",
              "Buy & Hold Return [%]              265.510909\n",
              "Return (Ann.) [%]                         0.0\n",
              "Volatility (Ann.) [%]                     NaN\n",
              "Sharpe Ratio                              NaN\n",
              "Sortino Ratio                             NaN\n",
              "Calmar Ratio                              0.0\n",
              "Max. Drawdown [%]                  -99.675341\n",
              "Avg. Drawdown [%]                  -99.675341\n",
              "Max. Drawdown Duration                 1005.0\n",
              "Avg. Drawdown Duration                 1005.0\n",
              "# Trades                                626.0\n",
              "Win Rate [%]                        11.022364\n",
              "Best Trade [%]                       0.698976\n",
              "Worst Trade [%]                     -3.483065\n",
              "Avg. Trade [%]                      -0.246606\n",
              "Max. Trade Duration                       1.0\n",
              "Avg. Trade Duration                  0.003195\n",
              "Profit Factor                        0.091033\n",
              "Expectancy [%]                      -0.245172\n",
              "SQN                                 -7.106897\n",
              "_strategy                 MLTrainOnceStrategy\n",
              "_equity_curve                         Equi...\n",
              "_trades                        Size  Entry...\n",
              "dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bt = Backtest(aapl_df, MLTrainOnceStrategy, commission=.0002, margin=.05)\n",
        "bt.run()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BenchMark\n",
        "After the strategies have been construct, we are going to use buy and hold and constance_rebalancing to compare the efficiency of the algorithm.\n",
        "We are using DRR, CRR, Varience, and Sharpe ratio to measure the performance of the benchmark algo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DRR\n",
        "The Daily rate of return can be computed by\n",
        "\n",
        "$$ DRR = { Price_{today} - Price_{prevday}} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# use DRR column\n",
        "def portfolio_daily_rate_of_return(portfolio_df, initial_amount):\n",
        "    if not ('DRR' in portfolio_df):\n",
        "        portfolio_df['DRR'] = np.nan\n",
        "    portfolio_df['DRR'] = ( portfolio_df['Sum'] - np.roll(portfolio_df['Sum'], shift=1))/portfolio_df['Sum']\n",
        "    portfolio_df.loc[portfolio_df.index[0], 'DRR']= (portfolio_df.loc[portfolio_df.index[0], 'Sum'] -initial_amount) /initial_amount\n",
        "    return portfolio_df \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CRR\n",
        "The Cumulative rate or the sum of the DRR can be computed by\n",
        "\n",
        "$$ CRR = { Price_{today} - Price_{init}} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# use CRR column\n",
        "def portfolio_cumulative_rate_of_return(portfolio_df, initial_amount):\n",
        "    if not ('DRR' in portfolio_df):\n",
        "        portfolio_df = portfolio_daily_rate_of_return(portfolio_df, initial_amount)\n",
        "    if not ('CRR' in portfolio_df):\n",
        "        portfolio_df['CRR'] = np.nan\n",
        "    \n",
        "    portfolio_df['CRR'] = ( portfolio_df['Sum'] - initial_amount)/initial_amount\n",
        "\n",
        "    return portfolio_df "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def portfolio_get_cumulative_rate_of_return(portfolio_df, index=-1):\n",
        "    return portfolio_df.loc[portfolio_df.index[index], 'CRR']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Varience\n",
        "The Varience can be computed by using the following equation\n",
        "\n",
        "$$ Var = { \\Sigma( DRR - E_{DRR} )^2 \\over Time} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def portfolio_varience(portfolio_df):\n",
        "    drr_sum = portfolio_df.loc[portfolio_df.index[-1], 'CRR']/portfolio_df.__len__()\n",
        "    diff_sq = np.square(portfolio_df['DRR'] - drr_sum)\n",
        "    var = diff_sq.sum()/portfolio_df.__len__()\n",
        "    return var"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sharpe ratio\n",
        "The ratio can be computed by using the following equation\n",
        "\n",
        "$$ Sharpe = { R_{portfolio} - R_{riskfree} \\over \\sigma_{portfolio}} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute the portfolio sharpe ratio\n",
        "def portfolio_sharpe_ratio(portfolio_df, port_sd, riskfree=0.0151, at_index=-1):\n",
        "    year_count = portfolio_df.__len__()/252\n",
        "    asset_return = portfolio_df.loc[portfolio_df.index[at_index], 'CRR']/year_count\n",
        "    return (asset_return - riskfree)/port_sd"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define a class for running rebalancing algo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConstanceBalancingOnTime:\n",
        "    def __init__(self, \n",
        "                df,\n",
        "                holding_ratio,\n",
        "                rebalance_time,\n",
        "                initial_amount,\n",
        "                transaction_cost_pct,\n",
        "                lookback=252,\n",
        "                day = 0):\n",
        "        self.df = df\n",
        "        self.rebalance_time = rebalance_time\n",
        "        self.holding_ratio = np.array(holding_ratio)\n",
        "        self.initial_amount = initial_amount\n",
        "        self.transaction_cost_pct = transaction_cost_pct\n",
        "        self.lookback = lookback\n",
        "        self.day = day\n",
        "\n",
        "        self.ticker_list = df[\"tic\"].unique()\n",
        "        self.stock_count = len(self.ticker_list)\n",
        "        # the first one is cash on hand followed by the stock in the tickers\n",
        "        self.asset_amount = self.holding_ratio * initial_amount\n",
        "\n",
        "        self.portfolio_memory = self._create_initial_memory()\n",
        "        self._write_memory_at_index(0)\n",
        "\n",
        "        #for keeping matric\n",
        "        self.metric = {}\n",
        "\n",
        "        \n",
        "\n",
        "    def step(self):\n",
        "        # incase \n",
        "        self.day += 1\n",
        "        # if (self.day == 1):\n",
        "        #     current_value = self.initial_amount / (self.transaction_cost_pct * self.holding_ratio[1:].sum() + self.initial_amount)\n",
        "        #     self.asset_amount = current_value * self.holding_ratio\n",
        "        #     return\n",
        "        \n",
        "        for index in range(self.stock_count):\n",
        "            try:\n",
        "                self.asset_amount[index+1] *= self._update_assetprice_by_ratio(int(self.day), self.ticker_list[index])\n",
        "            except:\n",
        "                print(\"error at day\",self.day, index)\n",
        "        \n",
        "        # rebalancing\n",
        "        if (self.day % self.rebalance_time == 0):\n",
        "\n",
        "            after_asset_amount = np.array([])\n",
        "            \n",
        "            current_asset_value = self.asset_amount.sum()\n",
        "            current_asset_ratio = self.asset_amount/current_asset_value\n",
        "\n",
        "            #check the sign of asset allowcation\n",
        "            asset_adapt_sign = self.holding_ratio >= current_asset_ratio\n",
        "                \n",
        "            asset_matrix = np.array([np.append(self.holding_ratio.copy(), 0)])\n",
        "            \n",
        "            for i in range(self.stock_count+1): \n",
        "                # the amount of add in that we will add into the asset line\n",
        "                add_in_asset_line = 1\n",
        "                if ((self.holding_ratio == current_asset_ratio)[i] ):\n",
        "                    pass\n",
        "                elif (asset_adapt_sign[i] ):\n",
        "                    add_in_asset_line += self.transaction_cost_pct\n",
        "                else:\n",
        "                    add_in_asset_line -= self.transaction_cost_pct\n",
        "                # print(add_in_asset_line)\n",
        "                current_asset_line = np.zeros(self.stock_count+2)\n",
        "                current_asset_line[i] = add_in_asset_line\n",
        "                current_asset_line[-1] = 1\n",
        "                # print(asset_matrix.shape, current_asset_line.shape)\n",
        "                # print(asset_matrix, current_asset_line)\n",
        "                asset_matrix = np.append(asset_matrix.copy(), np.array([current_asset_line.copy()]), axis=0)\n",
        "            asset_matrix = asset_matrix.T\n",
        "            \n",
        "            modify_amount = np.linalg.solve(asset_matrix, np.append(self.asset_amount, 0))[1:]\n",
        "            self.asset_amount = self.asset_amount - modify_amount\n",
        "        \n",
        "        # write the allocation to the memory df\n",
        "        self._write_memory_at_index(self.day)\n",
        "\n",
        "    def run(self):\n",
        "        time_range = self.df.__len__() / self.stock_count\n",
        "        for i in range(int(time_range)-1):\n",
        "            self.step()\n",
        "\n",
        "    def reset(self):\n",
        "        self.day = 0\n",
        "        self.asset_amount = self.holding_ratio * self.initial_amount\n",
        "\n",
        "        self.portfolio_memory = self._create_initial_memory()\n",
        "        self._write_memory_at_index(0)\n",
        "\n",
        "    def get_asset_amount(self):\n",
        "        return self.asset_amount.sum()\n",
        "    \n",
        "    def add_return(self, method):\n",
        "        self.portfolio_memory = method(self.portfolio_memory, self.initial_amount)\n",
        "\n",
        "    def add_metric(self, new_matric, new_matric_name, **kwargs):\n",
        "        matric_res = new_matric(self.portfolio_memory, **kwargs)\n",
        "        self.metric.update({new_matric_name: matric_res}) \n",
        "\n",
        "    def _create_initial_memory(self):\n",
        "        col = np.append(np.array(['Cash']), self.ticker_list)\n",
        "        col = np.append(col, np.array(['Sum']))\n",
        "        initial_memory = pd.DataFrame(index=self.df.index.unique(), columns=col)\n",
        "        \n",
        "        return initial_memory\n",
        "    \n",
        "    def _update_assetprice_by_ratio(self, time_index: int, ticker: str):\n",
        "        return self.df[self.df['tic'] == ticker].iloc[time_index]['Close']/self.df[self.df['tic'] == ticker].iloc[time_index-1]['Close']\n",
        "    \n",
        "    def _write_memory_at_index(self, index: int):\n",
        "        self.portfolio_memory.iloc[index]['Cash'] = self.asset_amount[0]\n",
        "        \n",
        "        for stock_index in range(self.stock_count):\n",
        "            current_ticker = self.ticker_list[stock_index]\n",
        "            self.portfolio_memory.iloc[index][current_ticker] = self.asset_amount[stock_index+1]\n",
        "        self.portfolio_memory.iloc[index]['Sum'] = self.asset_amount.sum()\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['AAPL', 'CAAS'], dtype=object)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mixed_df[\"tic\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df for testing\n",
        "test_df = mixed_df.copy().set_index('Date')\n",
        "risk_free_2022 = 0.025"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Single stock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "env_kwargs = {\n",
        "  \"holding_ratio\": [0, 0.5], \n",
        "  \"rebalance_time\": 60,\n",
        "  \"initial_amount\": 1000000, \n",
        "  \"transaction_cost_pct\": 0.001\n",
        "}\n",
        "\n",
        "cr = ConstanceBalancingOnTime(df = new_aapl_df.copy().set_index('Date'), **env_kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "cr.reset()\n",
        "cr.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "cr.add_return(portfolio_daily_rate_of_return)\n",
        "cr.add_return(portfolio_cumulative_rate_of_return)\n",
        "\n",
        "cr.add_metric(portfolio_varience, \"varience\")\n",
        "cr.add_metric(portfolio_get_cumulative_rate_of_return, \"crr\")\n",
        "env_kwargs = {\n",
        "  \"port_sd\": np.sqrt(cr.metric['varience']), \n",
        "  \"riskfree\": risk_free_2022,\n",
        "}\n",
        "\n",
        "cr.add_metric(portfolio_sharpe_ratio, \"sharpe\", **env_kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rebalance time 60\n",
            "initial amount 1000000\n",
            "tickers ['AAPL']\n",
            "stock count 1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'varience': 0.0007138874448694907,\n",
              " 'crr': 0.8275545459579413,\n",
              " 'sharpe': 6.815237131372679}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"rebalance time\", cr.rebalance_time)\n",
        "print(\"initial amount\", cr.initial_amount)\n",
        "print(\"tickers\", cr.ticker_list)\n",
        "print(\"stock count\", cr.stock_count)\n",
        "\n",
        "cr.metric"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Constance rebalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "env_kwargs = {\n",
        "  \"holding_ratio\": [0,0.5, 0.5], \n",
        "  \"rebalance_time\": 60,\n",
        "  \"initial_amount\": 1000000, \n",
        "  \"transaction_cost_pct\": 0.001\n",
        "}\n",
        "\n",
        "cr = ConstanceBalancingOnTime(df = test_df, **env_kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "cr.reset()\n",
        "cr.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "cr.add_return(portfolio_daily_rate_of_return)\n",
        "cr.add_return(portfolio_cumulative_rate_of_return)\n",
        "\n",
        "cr.add_metric(portfolio_varience, \"varience\")\n",
        "cr.add_metric(portfolio_get_cumulative_rate_of_return, \"crr\")\n",
        "env_kwargs = {\n",
        "  \"port_sd\": np.sqrt(cr.metric['varience']), \n",
        "  \"riskfree\": risk_free_2022,\n",
        "}\n",
        "\n",
        "cr.add_metric(portfolio_sharpe_ratio, \"sharpe\", **env_kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rebalance time 60\n",
            "initial amount 1000000\n",
            "tickers ['AAPL' 'CAAS']\n",
            "stock count 2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'varience': 0.0010014236330381694,\n",
              " 'crr': 2.60775359627078,\n",
              " 'sharpe': 19.831894080392228}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"rebalance time\", cr.rebalance_time)\n",
        "print(\"initial amount\", cr.initial_amount)\n",
        "print(\"tickers\", cr.ticker_list)\n",
        "print(\"stock count\", cr.stock_count)\n",
        "\n",
        "cr.metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Buy and Hold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "## let the time to be very high so the portfolio will not rebalance\n",
        "env_kwargs = {\n",
        "  \"holding_ratio\": [0,0.5,0.5], \n",
        "  \"rebalance_time\": 9999999999,\n",
        "  \"initial_amount\": 1000000, \n",
        "  \"transaction_cost_pct\": 0.001\n",
        "}\n",
        "\n",
        "buyhold = ConstanceBalancingOnTime(df = test_df, **env_kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "buyhold.reset()\n",
        "buyhold.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "buyhold.add_return(portfolio_daily_rate_of_return)\n",
        "buyhold.add_return(portfolio_cumulative_rate_of_return)\n",
        "buyhold.add_metric(portfolio_varience, \"varience\")\n",
        "buyhold.add_metric(portfolio_get_cumulative_rate_of_return, \"crr\")\n",
        "env_kwargs = {\n",
        "  \"port_sd\": np.sqrt(cr.metric['varience']), \n",
        "  \"riskfree\": risk_free_2022,\n",
        "}\n",
        "\n",
        "buyhold.add_metric(portfolio_sharpe_ratio, \"sharpe\", **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rebalance time 9999999999\n",
            "initial amount 1000000\n",
            "tickers ['AAPL' 'CAAS']\n",
            "stock count 2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'varience': 0.0006593813320346426,\n",
              " 'crr': 1.9875545841049216,\n",
              " 'sharpe': 14.927411207558738}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"rebalance time\", buyhold.rebalance_time)\n",
        "print(\"initial amount\", buyhold.initial_amount)\n",
        "print(\"tickers\", buyhold.ticker_list)\n",
        "print(\"stock count\", buyhold.stock_count)\n",
        "\n",
        "buyhold.metric\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
